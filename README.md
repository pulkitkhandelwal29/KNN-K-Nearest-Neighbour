# KNN (K Nearest Neighbour) Implementation

K-nearest neighbors (KNN) algorithm is a simple, easy-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems

In this particular notebook :- 
* Read the data
* Standardize the data
* Build Model using KNN
* To find the best K Neighbours **(used Elbow method)**

### Advantages
* Easy to implement (just needs K neighbour values and distance function)
* Algorithm is versatile. It can be used for classification, regression

### Disadvantages
* Does not work well with large dataset
* Does not work well with high dimensions
* Need feature scaling
* Sensitive to noisy data, missing values and outliers

KNNâ€™s main disadvantage of becoming significantly slower as the volume of data increases makes it an impractical choice in environments where predictions need to be made rapidly. Moreover, there are faster algorithms that can produce more accurate classification and regression results.
